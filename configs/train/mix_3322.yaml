# usa questo AL POSTO di baseline.yaml per allenare su 4 task insieme
tokenizer_file: "data/vocab/bpe.json"

datasets:
  - name: "rdf2text"
    train: "data/processed/rdf2text.train.jsonl"
    val:   "data/processed/rdf2text.val.jsonl"
    weight: 3
  - name: "text2rdf"
    train: "data/processed/text2rdf.train.jsonl"
    val:   "data/processed/text2rdf.val.jsonl"
    weight: 3
  - name: "rdfcomp1"
    train: "data/processed/rdfcomp1.train.jsonl"
    val:   "data/processed/rdfcomp1.val.jsonl"
    weight: 2
  - name: "rdfcomp2"
    train: "data/processed/rdfcomp2.train.jsonl"
    val:   "data/processed/rdfcomp2.val.jsonl"
    weight: 2

# modello
d_model: 384
nhead: 6
enc_layers: 3
dec_layers: 3
ff_dim: 1536
dropout: 0.1
max_len: 256

# training
batch_size: 16
lr: 3e-4
weight_decay: 0.01
warmup_steps: 2000
max_steps: 30000
eval_every: 1000
save_dir: "checkpoints/mix3322"
seed: 42
device: "cuda"
num_workers: 4
