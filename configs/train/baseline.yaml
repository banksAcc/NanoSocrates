train_file: "data/processed/text2rdf.train.jsonl"
val_file: "data/processed/text2rdf.val.jsonl"
tokenizer_file: "data/vocab/bpe.json"

# modello
d_model: 384
nhead: 6
enc_layers: 3
dec_layers: 3
ff_dim: 1536
dropout: 0.1
max_len: 256

# training
batch_size: 16
num_epochs: 10
gradient_accumulation_steps: 1
lr: 3e-4
weight_decay: 0.01
scheduler: "cosine"
warmup_ratio: 0.05
min_lr_ratio: 0.02
save_dir: "checkpoints/baseline"
seed: 42

device: "cuda"        # oppure "cpu"
num_workers: 4
