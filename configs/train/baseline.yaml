train_file: "data/processed/text2rdf.train.jsonl"
val_file: "data/processed/text2rdf.val.jsonl"
tokenizer_file: "data/vocab/bpe.json"

# modello
use_rope: false
use_mla: false
interleave_ratio: 0.0
d_model: 384
nhead: 6
enc_layers: 3
dec_layers: 3
ff_dim: 1536
dropout: 0.1
max_len: 256

# span masking (disabilitato)
enable_entity_spans: false
compute_span_metrics: false

# training
batch_size: 16
num_epochs: 10
gradient_accumulation_steps: 1
lr: 3e-4
weight_decay: 0.01
scheduler: "cosine"
warmup_ratio: 0.05
min_lr_ratio: 0.02
save_dir: "checkpoints/baseline"
seed: 42

device: "cuda"        # oppure "cpu"
num_workers: 4

wandb:
  mode: "disabled"      # usa "online" o "offline" per attivare il logging
  project: "nanosocrates"
  entity: null
  run_name: null
  tags: []
  watch: false
